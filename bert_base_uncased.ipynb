{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFiKhwY0eBhSGOUOBlybVI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "599e4bc7694b437f908f26c58de5a780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a12d2ac1920f46b29efb97d3ff746c78",
              "IPY_MODEL_b38677dd12aa4f6c8f6602da9df52836",
              "IPY_MODEL_298b850fbba3430a8b797f9f654e4a8c",
              "IPY_MODEL_5f9421e642924ab4b31d172337a57a4a"
            ],
            "layout": "IPY_MODEL_0ab09a4e3aa9444eb08f1346ae4fab97"
          }
        },
        "0b071d04d69242fab7230eb5980ada0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58aeb992d7e7454aad908e1f08275b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_a07ae9b47095429584fd5b2a78ffe6ab",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ff79c3c848714d37ad07fc8cbe3cb202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b3d4d7b69d7540c6866853e964818bbb",
            "placeholder": "​",
            "style": "IPY_MODEL_71380b53d134485390555f84c3ef7e76",
            "value": ""
          }
        },
        "8535ddd0a5fd42f49acb587f43cbdc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_109218ebe4f74ab284fd38ea97ce490f",
            "style": "IPY_MODEL_e970351099d14c0480c7706e5e7488f6",
            "value": true
          }
        },
        "336c20a866c74e899cfcee754a5a958f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_011d88d03602456baab5623f63b36c2f",
            "style": "IPY_MODEL_c8834dc6557a443cb2486d6f9ff06e6d",
            "tooltip": ""
          }
        },
        "4e3dcf12aed241f8ad56fa5b19565810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1b2a468ef2449192b1a4d9a1eb7928",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9f13aed5b949eeb6eb45332bcd0cab",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "0ab09a4e3aa9444eb08f1346ae4fab97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "58aeb992d7e7454aad908e1f08275b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07ae9b47095429584fd5b2a78ffe6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d4d7b69d7540c6866853e964818bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71380b53d134485390555f84c3ef7e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109218ebe4f74ab284fd38ea97ce490f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e970351099d14c0480c7706e5e7488f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "011d88d03602456baab5623f63b36c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8834dc6557a443cb2486d6f9ff06e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9e1b2a468ef2449192b1a4d9a1eb7928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9f13aed5b949eeb6eb45332bcd0cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87907c9131b246feb37987035e1d7be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6bc2ac0ee14f849f365572ea6dba0b",
            "placeholder": "​",
            "style": "IPY_MODEL_016f966902dd40c1b7b0d9bf9a2533da",
            "value": "Connecting..."
          }
        },
        "aa6bc2ac0ee14f849f365572ea6dba0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016f966902dd40c1b7b0d9bf9a2533da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12d2ac1920f46b29efb97d3ff746c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f29e58bd4a644abbb1ef3c387980101",
            "placeholder": "​",
            "style": "IPY_MODEL_ec91ea7e33ca421ba9a57d1ee9ed4ce1",
            "value": "Token is valid (permission: write)."
          }
        },
        "b38677dd12aa4f6c8f6602da9df52836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a7c74c3eef94b51919e6dc637924f98",
            "placeholder": "​",
            "style": "IPY_MODEL_30acc853e38a4f8e9a5743e1d5776b04",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "298b850fbba3430a8b797f9f654e4a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecabbb17f66a4730b72241fb103f38bd",
            "placeholder": "​",
            "style": "IPY_MODEL_210ac942c24a4c3a9127880303deff7d",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "5f9421e642924ab4b31d172337a57a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6698984758434d9539c68a1775b7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_234f763906994a87aba43f08ad13d502",
            "value": "Login successful"
          }
        },
        "2f29e58bd4a644abbb1ef3c387980101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec91ea7e33ca421ba9a57d1ee9ed4ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a7c74c3eef94b51919e6dc637924f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30acc853e38a4f8e9a5743e1d5776b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecabbb17f66a4730b72241fb103f38bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210ac942c24a4c3a9127880303deff7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff6698984758434d9539c68a1775b7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234f763906994a87aba43f08ad13d502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhurima5978/new/blob/main/bert_base_uncased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHb3MmPzyIR9",
        "outputId": "a2d991b7-8934-4a65-ec25-92a7c8a1911b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1: 100%|██████████| 381/381 [01:17<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.23168213573330892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 381/381 [01:17<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.16762905571245518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 381/381 [01:16<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 0.1299502490860779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 381/381 [01:16<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 0.10687568473288657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 381/381 [01:16<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 0.09045776272231708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine_tuned_model/tokenizer_config.json',\n",
              " 'fine_tuned_model/special_tokens_map.json',\n",
              " 'fine_tuned_model/vocab.txt',\n",
              " 'fine_tuned_model/added_tokens.json',\n",
              " 'fine_tuned_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Assuming you have a class to load your XML dataset into a suitable format\n",
        "class ABSADataset(Dataset):\n",
        "    def __init__(self, xml_file, tokenizer, max_seq_length=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.data = self._load_data(xml_file)\n",
        "\n",
        "    def _load_data(self, xml_file):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        data = []\n",
        "        for review in root.findall(\".//sentence\"):\n",
        "            text = review.find(\"text\").text\n",
        "            aspect_terms = []\n",
        "            for aspect_term in review.findall(\".//aspectTerm\"):\n",
        "                term = aspect_term.get(\"term\")\n",
        "                polarity = aspect_term.get(\"polarity\")\n",
        "                from_pos = int(aspect_term.get(\"from\"))\n",
        "                to_pos = int(aspect_term.get(\"to\"))\n",
        "                aspect_terms.append({\n",
        "                    \"term\": term,\n",
        "                    \"polarity\": polarity,\n",
        "                    \"from\": from_pos,\n",
        "                    \"to\": to_pos\n",
        "                })\n",
        "\n",
        "            data.append({\n",
        "                \"text\": text,\n",
        "                \"aspect_terms\": aspect_terms\n",
        "            })\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item[\"text\"]\n",
        "        aspect_terms = item[\"aspect_terms\"]\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_seq_length,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        labels = torch.zeros(self.max_seq_length, dtype=torch.long)\n",
        "        for aspect_term in aspect_terms:\n",
        "            from_pos = min(aspect_term[\"from\"], self.max_seq_length - 1)\n",
        "            to_pos = min(aspect_term[\"to\"], self.max_seq_length - 1)\n",
        "            labels[from_pos:to_pos + 1] = self.map_label_to_int(aspect_term[\"polarity\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "    def map_label_to_int(self, label):\n",
        "        label_mapping = {\"positive\": 1, \"negative\": 2, \"neutral\": 3}\n",
        "        return label_mapping[label] if label in label_mapping else 0  # Default to 0 for unknown labels\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Sort the batch by sequence length (in descending order)\n",
        "    batch = sorted(batch, key=lambda x: len(x[\"input_ids\"]), reverse=True)\n",
        "\n",
        "    # Extract inputs and labels\n",
        "    inputs = [item[\"input_ids\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "\n",
        "    # Pad sequences to the length of the longest sequence in the batch\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)  # Assuming 0 is the padding value for labels\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = (inputs_padded != tokenizer.pad_token_id).int()\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs_padded,\n",
        "        \"labels\": labels_padded,\n",
        "        \"attention_mask\": attention_mask\n",
        "    }\n",
        "\n",
        "# Load your ABSA dataset and tokenizer\n",
        "xml_file = \"Laptop_Train_v2.xml\"  # Replace with your actual file path\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_dataset = ABSADataset(xml_file, tokenizer)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_name = \"bert-base-uncased\"\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = 4  # Number of labels: positive, negative, neutral, padding\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "# Fine-tune your model using the DataLoader and collate function\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Specify training parameters, optimizer, and loss function\n",
        "num_epochs = 5\n",
        "learning_rate = 5e-5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "DEZl84zS2YoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "599e4bc7694b437f908f26c58de5a780",
            "0b071d04d69242fab7230eb5980ada0c",
            "ff79c3c848714d37ad07fc8cbe3cb202",
            "8535ddd0a5fd42f49acb587f43cbdc23",
            "336c20a866c74e899cfcee754a5a958f",
            "4e3dcf12aed241f8ad56fa5b19565810",
            "0ab09a4e3aa9444eb08f1346ae4fab97",
            "58aeb992d7e7454aad908e1f08275b7f",
            "a07ae9b47095429584fd5b2a78ffe6ab",
            "b3d4d7b69d7540c6866853e964818bbb",
            "71380b53d134485390555f84c3ef7e76",
            "109218ebe4f74ab284fd38ea97ce490f",
            "e970351099d14c0480c7706e5e7488f6",
            "011d88d03602456baab5623f63b36c2f",
            "c8834dc6557a443cb2486d6f9ff06e6d",
            "9e1b2a468ef2449192b1a4d9a1eb7928",
            "cb9f13aed5b949eeb6eb45332bcd0cab",
            "87907c9131b246feb37987035e1d7be2",
            "aa6bc2ac0ee14f849f365572ea6dba0b",
            "016f966902dd40c1b7b0d9bf9a2533da",
            "a12d2ac1920f46b29efb97d3ff746c78",
            "b38677dd12aa4f6c8f6602da9df52836",
            "298b850fbba3430a8b797f9f654e4a8c",
            "5f9421e642924ab4b31d172337a57a4a",
            "2f29e58bd4a644abbb1ef3c387980101",
            "ec91ea7e33ca421ba9a57d1ee9ed4ce1",
            "0a7c74c3eef94b51919e6dc637924f98",
            "30acc853e38a4f8e9a5743e1d5776b04",
            "ecabbb17f66a4730b72241fb103f38bd",
            "210ac942c24a4c3a9127880303deff7d",
            "ff6698984758434d9539c68a1775b7cc",
            "234f763906994a87aba43f08ad13d502"
          ]
        },
        "id": "UzN6_RCJ2jIh",
        "outputId": "2ff681bd-f4b8-4fd9-e64c-adc3cf2a4200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "599e4bc7694b437f908f26c58de5a780"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")\n"
      ],
      "metadata": {
        "id": "cEssmiGh3gqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationDataset(Dataset):\n",
        "    def __init__(self, xml_file, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = self._load_data(xml_file)\n",
        "\n",
        "    def _load_data(self, xml_file):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        data = []\n",
        "        for sentence in root.findall(\".//sentence\"):\n",
        "            text = sentence.find(\"text\").text\n",
        "            aspect_terms = []\n",
        "            for aspect_term in sentence.findall(\".//aspectTerm\"):\n",
        "                term = aspect_term.get(\"term\")\n",
        "                polarity = aspect_term.get(\"polarity\")\n",
        "                from_pos = int(aspect_term.get(\"from\"))\n",
        "                to_pos = int(aspect_term.get(\"to\"))\n",
        "                aspect_terms.append({\n",
        "                    \"term\": term,\n",
        "                    \"polarity\": polarity,\n",
        "                    \"from\": from_pos,\n",
        "                    \"to\": to_pos\n",
        "                })\n",
        "\n",
        "            data.append({\n",
        "                \"text\": text,\n",
        "                \"aspect_terms\": aspect_terms\n",
        "            })\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item[\"text\"]\n",
        "        aspect_terms = item[\"aspect_terms\"]\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=128,  # Adjust as needed\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "        labels = torch.zeros(128, dtype=torch.long)  # Assuming max_length is 128\n",
        "        for aspect_term in aspect_terms:\n",
        "            from_pos = min(aspect_term[\"from\"], 127)  # 127 is max_length - 1\n",
        "            to_pos = min(aspect_term[\"to\"], 127)\n",
        "            labels[from_pos:to_pos + 1] = self.map_label_to_int(aspect_term[\"polarity\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "    def map_label_to_int(self, label):\n",
        "        label_mapping = {\"positive\": 1, \"negative\": 2, \"neutral\": 3}\n",
        "        return label_mapping[label] if label in label_mapping else 0  # Default to 0 for unknown labels\n",
        "\n",
        "# Define your collate function\n",
        "def collate_fn(batch):\n",
        "    batch = sorted(batch, key=lambda x: len(x[\"input_ids\"]), reverse=True)\n",
        "    inputs = [item[\"input_ids\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
        "    attention_mask = (inputs_padded != tokenizer.pad_token_id).int()\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs_padded,\n",
        "        \"labels\": labels_padded,\n",
        "        \"attention_mask\": attention_mask\n",
        "    }\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Create the validation dataset and data loader\n",
        "validation_dataset = ValidationDataset(\"laptops-trial.xml\", tokenizer)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=8, collate_fn=collate_fn)\n",
        "\n",
        "# Validation loop\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(validation_loader, desc=\"Validation\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=2).squeeze()\n",
        "\n",
        "        # Count correct predictions\n",
        "        total_correct += (predicted_labels == labels).sum().item()\n",
        "        total_samples += labels.numel()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_oz63ZS32Gf",
        "outputId": "583ee297-54c6-494f-db54-ea1902a8253a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 13/13 [00:00<00:00, 15.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 97.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config.num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaPAecFr77Mw",
        "outputId": "2889ee78-97cb-43ba-bb6a-a46c228f9eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")\n",
        "input_sentence = \"I don't like the laptop design but its battery life is good\"\n",
        "inputs = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "print(inputs)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(outputs.logits)\n",
        "\n",
        "predicted_labels = torch.argmax(outputs.logits, dim=2).squeeze().tolist()\n",
        "predicted_labels_decoded = tokenizer.batch_decode(predicted_labels)\n",
        "\n",
        "print(predicted_labels_decoded)\n",
        "label_mapping = {1: \"positive\", 2: \"negative\", 3: \"neutral\"}\n",
        "\n",
        "# Extract aspects and sentiments\n",
        "aspects = []\n",
        "sentiments = []\n",
        "\n",
        "current_aspect = None\n",
        "current_sentiment = None\n",
        "for token, label_id in zip(tokenizer.tokenize(input_sentence), predicted_labels_decoded[0]):\n",
        "    label = label_mapping.get(label_id, None)\n",
        "\n",
        "    if label is None or label == \"[pad]\":\n",
        "        continue\n",
        "    if current_aspect is None:\n",
        "        current_aspect = token\n",
        "        current_sentiment = label\n",
        "    elif label == current_sentiment:\n",
        "        current_aspect += f\" {token}\"\n",
        "    else:\n",
        "        aspects.append(current_aspect)\n",
        "        sentiments.append(current_sentiment)\n",
        "        current_aspect = token\n",
        "        current_sentiment = label\n",
        "\n",
        "if current_aspect is not None:\n",
        "    aspects.append(current_aspect)\n",
        "    sentiments.append(current_sentiment)\n",
        "\n",
        "# Print or use the extracted aspects and sentiments\n",
        "for aspect, sentiment in zip(aspects, sentiments):\n",
        "    print(f\"Aspect: {aspect}\\nSentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4hPmaff7JR8",
        "outputId": "f7412757-abba-464d-886e-81d407723ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  2123,  1005,  1056,  2066,  1996, 12191,  2640,  2021,\n",
            "          2049,  6046,  2166,  2003,  2204,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "tensor([[[ 7.7998, -2.7625, -2.7599, -2.4968],\n",
            "         [ 7.6707, -2.8084, -2.8279, -2.3984],\n",
            "         [ 7.7099, -2.8112, -2.8755, -2.5009],\n",
            "         [ 7.7191, -2.8092, -2.8058, -2.5985],\n",
            "         [ 7.7378, -2.8216, -2.8980, -2.5429],\n",
            "         [ 7.5982, -2.7552, -2.8988, -2.5706],\n",
            "         [ 7.5434, -2.6632, -2.5479, -2.6122],\n",
            "         [ 7.7524, -2.7728, -2.6132, -2.5914],\n",
            "         [ 7.3784, -2.3706, -2.6503, -2.3804],\n",
            "         [ 7.5770, -2.5950, -2.5655, -2.6020],\n",
            "         [ 7.0114, -1.9806, -2.5963, -2.4753],\n",
            "         [ 6.4649, -1.4167, -2.7726, -2.3893],\n",
            "         [ 5.7148, -0.8626, -2.8013, -2.4827],\n",
            "         [ 6.3804, -1.6774, -2.6779, -2.5248],\n",
            "         [ 6.0397, -1.2942, -2.7517, -2.8501],\n",
            "         [ 4.5874, -0.6020, -1.8783, -2.7252]]])\n",
            "['[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model\")\n",
        "# Replace 'Your new input sentence here.' with your actual input sentence\n",
        "input_sentence = 'The laptops performance is good but battery life is bad'\n",
        "\n",
        "# Tokenize and encode the input sentence\n",
        "inputs = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "# Perform inference using the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Access the logits or predicted labels\n",
        "logits = outputs.logits\n",
        "predicted_labels = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "# Decode predicted labels using the tokenizer\n",
        "predicted_labels_decoded = tokenizer.batch_decode(predicted_labels)\n",
        "# Extract aspects and sentiments from the decoded labels\n",
        "aspects = []\n",
        "sentiments = []\n",
        "\n",
        "for token, label in zip(tokenizer.tokenize(input_sentence), predicted_labels_decoded):\n",
        "    if label != \"O\":  # \"O\" typically represents tokens outside aspect terms\n",
        "        aspects.append(token)\n",
        "        sentiments.append(label.lower())  # Assuming labels are \"positive\", \"negative\", \"neutral\"\n",
        "\n",
        "# Print or use the extracted aspects and sentiments\n",
        "print(\"Aspects:\", aspects)\n",
        "print(\"Sentiments:\", sentiments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBfUG8FB430G",
        "outputId": "773f2751-3cfd-4abe-bf38-487057a1adeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspects: ['the', 'laptop', '##s', 'performance', 'is', 'good', 'but', 'battery', 'life', 'is', 'bad']\n",
            "Sentiments: ['[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the labels are \"positive\", \"negative\", \"neutral\"\n",
        "label_mapping = {1: \"positive\", 2: \"negative\", 3: \"neutral\"}\n",
        "\n",
        "# Initialize variables to store aspects and sentiments\n",
        "current_aspect = None\n",
        "current_sentiment = None\n",
        "aspects = []\n",
        "sentiments = []\n",
        "\n",
        "# Iterate over tokens and labels\n",
        "for token, label_id in zip(tokenizer.tokenize(input_sentence), predicted_labels):\n",
        "    label = label_mapping.get(label_id, None)\n",
        "\n",
        "    # Handle the case where the label is not mapped or it is a pad token\n",
        "    if label is None or label == \"[pad]\":\n",
        "        continue\n",
        "\n",
        "    # Check if the current token is part of the same aspect term\n",
        "    if current_aspect is None:\n",
        "        current_aspect = token\n",
        "        current_sentiment = label\n",
        "    elif label == current_sentiment:\n",
        "        current_aspect += f\" {token}\"\n",
        "    else:\n",
        "        # Save the current aspect and sentiment\n",
        "        aspects.append(current_aspect)\n",
        "        sentiments.append(current_sentiment)\n",
        "\n",
        "        # Reset variables for the next aspect term\n",
        "        current_aspect = token\n",
        "        current_sentiment = label\n",
        "\n",
        "# Check if there is an aspect term remaining\n",
        "if current_aspect is not None:\n",
        "    aspects.append(current_aspect)\n",
        "    sentiments.append(current_sentiment)\n",
        "\n",
        "# Print or use the extracted aspects and sentiments\n",
        "for aspect, sentiment in zip(aspects, sentiments):\n",
        "    print(f\"{aspect}: {sentiment}\")\n"
      ],
      "metadata": {
        "id": "Em7S3n4m55vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the sentiment analysis model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
        "\n",
        "# Define a simple dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'text': self.texts[idx], 'label': self.labels[idx]}\n",
        "\n",
        "# Fine-tuning parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-5\n",
        "\n",
        "# Load and parse the XML dataset\n",
        "tree = ET.parse('Laptop_Train_v2.xml')\n",
        "root = tree.getroot()\n",
        "\n",
        "# Initialize lists to store text and labels\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each 'sentence' element in the XML\n",
        "for sentence in root.findall('.//sentence'):\n",
        "    text = sentence.find('text').text.strip()\n",
        "\n",
        "    # Check if the 'aspectTerms' element exists\n",
        "    aspect_terms = sentence.find('aspectTerms')\n",
        "    if aspect_terms is not None:\n",
        "        # Iterate through each 'aspectTerm' element\n",
        "        for aspect_term in aspect_terms.findall('aspectTerm'):\n",
        "            term = aspect_term.get('term')\n",
        "            polarity = aspect_term.get('polarity', 'neutral')\n",
        "\n",
        "            # Append to the lists\n",
        "            texts.append(text)\n",
        "            labels.append(polarity)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(df))\n",
        "train_data = SentimentDataset(df['text'][:train_size], df['label'][:train_size])\n",
        "val_data = SentimentDataset(df['text'][train_size:], df['label'][train_size:])\n",
        "\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=2, shuffle=False)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_text = batch['text']\n",
        "        labels = tokenizer(batch['label'], return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
        "        # Perform forward pass with specified 'labels'\n",
        "        output = model(input_ids=tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)[\"input_ids\"], labels=labels)\n",
        "\n",
        "        # Retrieve the loss from the output\n",
        "        loss = output.loss\n",
        "\n",
        "        # Perform backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(epoch)\n",
        "\n",
        "\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine_tuned_model\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"fine_tuned_model\")\n",
        "\n",
        "# Perform sentiment analysis on a sample text\n",
        "sample_text = \"I love the performance of this laptop.\"\n",
        "# Perform forward pass\n",
        "tokenized_text = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "output = model.generate(tokenized_text.input_ids)\n",
        "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the sentiment analysis result\n",
        "print(\"Sentiment Analysis Result:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "PWtVqAHwACap",
        "outputId": "6eee5d69-1ffd-47d9-f011-845c09745c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2b263ca47cab>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Perform backward pass and optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}